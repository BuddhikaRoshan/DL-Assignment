{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhP8Zi9LK9Y/BGZiVYZFrl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BuddhikaRoshan/Deep-Learning-Assignment/blob/sonaliliyanahetti-patch-1/IT22592088.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chest X-ray lung cancer image classification task. This approach utilizes the ResNet50 architecture for Transfer Learning after performing essential data preprocessing, including extraction, resizing, and splitting the dataset into training and validation** **sets** **bold text** **bold text** **bold text** **bold text**"
      ],
      "metadata": {
        "id": "rM8sDy1hjEep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5NcQbkRbOYK",
        "outputId": "16d7b9ec-1aa0-48ec-ca03-175e7833bf0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "QOvdGFHCbnl-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Extraction"
      ],
      "metadata": {
        "id": "AV6QZssLdVlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = '/content/drive/MyDrive/DL/lung_images.zip'\n",
        "\n",
        "\n",
        "from zipfile import ZipFile #to extract .zip files.\n",
        "import cv2 #for reading and resizing images\n",
        "import gc\n",
        "import os\n",
        "\n",
        "#Opens the ZIP file from Drive and extracts all images into\n",
        "#a folder named 'lung_images'.\n",
        "with ZipFile(dataset_url,'r') as zip:\n",
        "  zip.extractall()\n",
        "print('The data set has been extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQswYG51dhr2",
        "outputId": "531497d4-306d-46de-9146-a54bdf483fa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data set has been extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preparation**"
      ],
      "metadata": {
        "id": "3oaU76XwnfBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path ='lung_images'#unzipped folder name\n",
        "classes=['lung_n','lung_aca']\n",
        " #two classes,\n",
        "#lung_n → normal lungs\n",
        "#lung_aca → lungs with adenocarcinoma (cancer)#binary classification"
      ],
      "metadata": {
        "id": "V8zBTaUofCur"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Img_Size=256 #pixel size\n",
        "Split=0.2 #20% for validation\n",
        "epochs=10 #train upto\n",
        "Batch_size=64 #64 images are processed per training step"
      ],
      "metadata": {
        "id": "IPeVOQqboNKv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "#loading and preprocess data\n",
        "\n",
        "x,y = [], [] #pixel value,class numbers\n",
        "\n",
        "#loop through class\n",
        "for i,cate in enumerate(classes):#enumerate: built in function to get both value and index no\n",
        "  #glob-find all image paths in each class folder.\n",
        "  images= glob.glob(f'{path}/{cate}/*.jpeg')\n",
        "  for img in images:\n",
        "    #read images using OpenCV\n",
        "    #It converts the image file into a NumPy array of pixel values\n",
        "    img= cv2.imread(img)\n",
        "    img=cv2.resize(img,(Img_Size,Img_Size))\n",
        "    x.append(img)\n",
        "    y.append(i)"
      ],
      "metadata": {
        "id": "V4PKzSXjpZtW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalize and One-Hot Encode**"
      ],
      "metadata": {
        "id": "2aBii-Uel1ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure x and y are treated as numpy arrays\n",
        "X = np.asarray(x) / 255.0  # normalize\n",
        "one_hot_encoded_Y = pd.get_dummies(np.asarray(y)).values"
      ],
      "metadata": {
        "id": "trp58vO6l8kk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split into train and Validation**"
      ],
      "metadata": {
        "id": "hq1WAfPInsgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, one_hot_encoded_Y, test_size=Split, random_state=2022)"
      ],
      "metadata": {
        "id": "FmGdTQoOnW_Z"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}